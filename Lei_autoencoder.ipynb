{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('DeepLatentMicrobiome/Src/')\n",
    "from layers import *\n",
    "from data import *\n",
    "from train import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto, encoder_bioma, encoder_domain, decoder_bioma = autoencoder(domain_shape = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer name: bioma_input_717\n",
      "Input shape: [(None, 717)]\n",
      "Output shape: [(None, 717)]\n",
      "not activation\n",
      "no weights\n",
      "no weights\n",
      "\n",
      "Layer name: center_log_ratio\n",
      "Input shape: (None, 717)\n",
      "Output shape: (None, 717)\n",
      "not activation\n",
      "no weights\n",
      "no weights\n",
      "\n",
      "Layer name: encoder_bioma_dense_128\n",
      "Input shape: (None, 717)\n",
      "Output shape: (None, 128)\n",
      "not activation\n",
      "Number of weights: 717\n",
      "Number of biases: 128\n",
      "\n",
      "Layer name: encoder_bioma_dense_64\n",
      "Input shape: (None, 128)\n",
      "Output shape: (None, 64)\n",
      "not activation\n",
      "Number of weights: 128\n",
      "Number of biases: 64\n",
      "\n",
      "Layer name: encoded_bioma_10\n",
      "Input shape: (None, 64)\n",
      "Output shape: (None, 10)\n",
      "Activation function: tanh\n",
      "Number of weights: 64\n",
      "Number of biases: 10\n",
      "\n",
      "Layer name: decoder_dense_64\n",
      "Input shape: (None, 10)\n",
      "Output shape: (None, 64)\n",
      "not activation\n",
      "Number of weights: 10\n",
      "Number of biases: 64\n",
      "\n",
      "Layer name: decoder_dense_128\n",
      "Input shape: (None, 64)\n",
      "Output shape: (None, 128)\n",
      "not activation\n",
      "Number of weights: 64\n",
      "Number of biases: 128\n",
      "\n",
      "Layer name: decoded_bioma\n",
      "Input shape: (None, 128)\n",
      "Output shape: (None, 717)\n",
      "Activation function: linear\n",
      "Number of weights: 128\n",
      "Number of biases: 717\n",
      "\n",
      "Layer name: bioma\n",
      "Input shape: (None, 717)\n",
      "Output shape: (None, 717)\n",
      "not activation\n",
      "no weights\n",
      "no weights\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for layer in auto.layers:\n",
    "    # Print the layer name\n",
    "    print(\"Layer name:\", layer.name)\n",
    "    # Print the input shape of the layer\n",
    "    print(\"Input shape:\", layer.input_shape)\n",
    "    # Print the output shape of the layer\n",
    "    print(\"Output shape:\", layer.output_shape)\n",
    "    # Print the activation function of the layer\n",
    "    try: \n",
    "        print(\"Activation function:\", layer.activation.__name__)\n",
    "    except:\n",
    "        print(\"not activation\")\n",
    "    # Print the number of weights and biases of the layer\n",
    "    try: \n",
    "        print(\"Number of weights:\", len(layer.get_weights()[0]))\n",
    "    except:\n",
    "        print(\"no weights\")\n",
    "    try: \n",
    "        print(\"Number of biases:\", len(layer.get_weights()[1]))\n",
    "    except:\n",
    "        print(\"no weights\")\n",
    "    # Print a blank line for readability\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"EncoderBioma\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bioma_input_717 (InputLayer  [(None, 717)]            0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " center_log_ratio (CenterLog  (None, 717)              0         \n",
      " Ratio)                                                          \n",
      "                                                                 \n",
      " encoder_bioma_dense_128 (De  (None, 128)              91904     \n",
      " nse)                                                            \n",
      "                                                                 \n",
      " encoder_bioma_dense_64 (Den  (None, 64)               8256      \n",
      " se)                                                             \n",
      "                                                                 \n",
      " encoded_bioma_10 (Dense)    (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 100,810\n",
      "Trainable params: 100,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_bioma.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " center_log_ratio (CenterLog  (None, 717)              0         \n",
      " Ratio)                                                          \n",
      "                                                                 \n",
      " encode_128 (Dense)          (None, 128)               91904     \n",
      "                                                                 \n",
      " encode_64 (Dense)           (None, 64)                8256      \n",
      "                                                                 \n",
      " encode_10 (Dense)           (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 100,810\n",
      "Trainable params: 100,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"DecoderBioma\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " latent_space_input (InputLa  [(None, 10)]             0         \n",
      " yer)                                                            \n",
      "                                                                 \n",
      " decoder_dense_64 (Dense)    (None, 64)                704       \n",
      "                                                                 \n",
      " decoder_dense_128 (Dense)   (None, 128)               8320      \n",
      "                                                                 \n",
      " decoded_bioma (Dense)       (None, 717)               92493     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 101,517\n",
      "Trainable params: 101,517\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder_bioma.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " decode_64 (Dense)           (None, 64)                704       \n",
      "                                                                 \n",
      " decode_128 (Dense)          (None, 128)               8320      \n",
      "                                                                 \n",
      " decode_717 (Dense)          (None, 717)               92493     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 101,517\n",
      "Trainable params: 101,517\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "otu_size = 717\n",
    "latent_size = 10\n",
    "hidden_layers = [128, 64]\n",
    "encoder = keras.Sequential([\n",
    "    CenterLogRatio(),\n",
    "    layers.Dense(128,  name = \"encode_128\"),\n",
    "    layers.Dense(64, name = \"encode_64\"),\n",
    "    layers.Dense(10, activation = 'tanh', name = \"encode_10\")\n",
    "], name = \"encoder\")\n",
    "decoder = keras.Sequential([\n",
    "    layers.Dense(64, input_shape = (10,),name = \"decode_64\"),\n",
    "    layers.Dense(128,  name = \"decode_128\"),\n",
    "    layers.Dense(717, activation = 'linear', name = \"decode_717\")\n",
    "], name = \"decoder\")\n",
    "input_layer = layers.Input(shape = (otu_size,), name = \"input_layer\")\n",
    "latent_vector = encoder(input_layer)\n",
    "output = decoder(latent_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (InputLayer)    [(None, 717)]             0         \n",
      "                                                                 \n",
      " encoder (Sequential)        (None, 10)                100810    \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| center_log_ratio (CenterLog  (None, 717)            0         |\n",
      "| Ratio)                                                        |\n",
      "|                                                               |\n",
      "| encode_128 (Dense)        (None, 128)               91904     |\n",
      "|                                                               |\n",
      "| encode_64 (Dense)         (None, 64)                8256      |\n",
      "|                                                               |\n",
      "| encode_10 (Dense)         (None, 10)                650       |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      " decoder (Sequential)        (None, 717)               101517    \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| decode_64 (Dense)         (None, 64)                704       |\n",
      "|                                                               |\n",
      "| decode_128 (Dense)        (None, 128)               8320      |\n",
      "|                                                               |\n",
      "| decode_717 (Dense)        (None, 717)               92493     |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      "=================================================================\n",
      "Total params: 202,327\n",
      "Trainable params: 202,327\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Model(inputs = input_layer, outputs = output)\n",
    "model.compile(\"adam\", loss = \"mean_squared_error\")\n",
    "model.summary(expand_nested = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, __, __, otu_columns, __ = read_data(otu_filename = 'DeepLatentMicrobiome/Datasets/otu_table_all_80.csv', \n",
    "metadata_filename = 'DeepLatentMicrobiome/Datasets/metadata_table_all_80.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " 1/67 [..............................] - ETA: 23s - loss: 384476.9375"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-24 09:16:00.344062: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 1s 9ms/step - loss: 416378.0938\n",
      "Epoch 2/50\n",
      "67/67 [==============================] - 1s 9ms/step - loss: 405233.3438\n",
      "Epoch 3/50\n",
      "67/67 [==============================] - 1s 7ms/step - loss: 371411.1875\n",
      "Epoch 4/50\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 339515.1562\n",
      "Epoch 5/50\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 323606.4688\n",
      "Epoch 6/50\n",
      "67/67 [==============================] - 1s 7ms/step - loss: 326151.1875\n",
      "Epoch 7/50\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 326930.2188\n",
      "Epoch 8/50\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 323745.8750\n",
      "Epoch 9/50\n",
      "67/67 [==============================] - 1s 9ms/step - loss: 304198.0938\n",
      "Epoch 10/50\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 302771.9062\n",
      "Epoch 11/50\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 307357.2500\n",
      "Epoch 12/50\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 289885.5312\n",
      "Epoch 13/50\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 283412.7812\n",
      "Epoch 14/50\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 299023.3125\n",
      "Epoch 15/50\n",
      "67/67 [==============================] - 1s 10ms/step - loss: 297599.5312\n",
      "Epoch 16/50\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 283091.1250\n",
      "Epoch 17/50\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 275691.6562\n",
      "Epoch 18/50\n",
      "67/67 [==============================] - 1s 7ms/step - loss: 275259.1562\n",
      "Epoch 19/50\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 279322.7812\n",
      "Epoch 20/50\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 282915.5000\n",
      "Epoch 21/50\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 283675.0625\n",
      "Epoch 22/50\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 278563.9688\n",
      "Epoch 23/50\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 268773.3125\n",
      "Epoch 24/50\n",
      "67/67 [==============================] - 1s 7ms/step - loss: 282243.6875\n",
      "Epoch 25/50\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 260721.9062\n",
      "Epoch 26/50\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 252061.1719\n",
      "Epoch 27/50\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 252148.6875\n",
      "Epoch 28/50\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 248208.1094\n",
      "Epoch 29/50\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 244642.1094\n",
      "Epoch 30/50\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 238427.7656\n",
      "Epoch 31/50\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 248598.4531\n",
      "Epoch 32/50\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 234008.5000\n",
      "Epoch 33/50\n",
      "67/67 [==============================] - 1s 9ms/step - loss: 250666.7344\n",
      "Epoch 34/50\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 236743.5156\n",
      "Epoch 35/50\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 254688.2969\n",
      "Epoch 36/50\n",
      "67/67 [==============================] - 1s 9ms/step - loss: 251634.1250\n",
      "Epoch 37/50\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 239107.1875\n",
      "Epoch 38/50\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 271087.1875\n",
      "Epoch 39/50\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 247090.2500\n",
      "Epoch 40/50\n",
      "67/67 [==============================] - 1s 12ms/step - loss: 238255.3125\n",
      "Epoch 41/50\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 220608.2812\n",
      "Epoch 42/50\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 229657.8438\n",
      "Epoch 43/50\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 232378.8438\n",
      "Epoch 44/50\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 221018.6719\n",
      "Epoch 45/50\n",
      "67/67 [==============================] - 1s 9ms/step - loss: 239766.0156\n",
      "Epoch 46/50\n",
      "67/67 [==============================] - 1s 9ms/step - loss: 223265.5000\n",
      "Epoch 47/50\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 221883.4219\n",
      "Epoch 48/50\n",
      "67/67 [==============================] - 1s 9ms/step - loss: 215194.7344\n",
      "Epoch 49/50\n",
      "67/67 [==============================] - 1s 9ms/step - loss: 213999.6875\n",
      "Epoch 50/50\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 222953.0781\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cf7b5820>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, X_train, epochs = 50, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
